{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a0fad64-e7fb-422a-bb8a-b72b9a6b338e",
   "metadata": {},
   "source": [
    "# Handle Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cc38adf-aa2c-4d20-b5c3-b7a7386dea19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('/home/aforestier10/Downloads/spark-3.5.3-bin-hadoop3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05a1fc5d-cfdd-4d41-aaf1-eebd29711fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1527b37c-f131-4edf-8502-21364bef5d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('Agg').getOrCreate()\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb51a43f-c4dd-4c5a-bdfa-60e57bec51e1",
   "metadata": {},
   "source": [
    "### Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4738b9a-b7f9-45dc-80e2-b73378b176e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv('ContainsNull.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e438c111-d34c-4ae4-8d5b-811b28b416b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----+\n",
      "|  Id| Name|Sales|\n",
      "+----+-----+-----+\n",
      "|emp1| John| NULL|\n",
      "|emp2| NULL| NULL|\n",
      "|emp3| NULL|345.0|\n",
      "|emp4|Cindy|456.0|\n",
      "+----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81697fc-32f4-46e7-96b6-dd2e72fb42ec",
   "metadata": {},
   "source": [
    "### Drop Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5243790-1afc-4956-ad62-cc467f467cfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----+\n",
      "|  Id| Name|Sales|\n",
      "+----+-----+-----+\n",
      "|emp4|Cindy|456.0|\n",
      "+----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Drops any row w/ missing data\n",
    "df.na.drop().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84e103e4-3d9d-4df9-a049-e90d42d16de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----+\n",
      "|  Id| Name|Sales|\n",
      "+----+-----+-----+\n",
      "|emp1| John| NULL|\n",
      "|emp3| NULL|345.0|\n",
      "|emp4|Cindy|456.0|\n",
      "+----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set threshold of non null values to not drop\n",
    "# in this example, row must have at least 2 non-null values to not be dropped\n",
    "df.na.drop(thresh=2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ade4be8-ad73-413f-ad85-054922a7596d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----+\n",
      "|  Id| Name|Sales|\n",
      "+----+-----+-----+\n",
      "|emp1| John| NULL|\n",
      "|emp2| NULL| NULL|\n",
      "|emp3| NULL|345.0|\n",
      "|emp4|Cindy|456.0|\n",
      "+----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Can specify how - i.e. 'all' means all must be null\n",
    "df.na.drop(how='all').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cda07a46-0961-494c-aeaf-c577f6ef36e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----+\n",
      "|  Id| Name|Sales|\n",
      "+----+-----+-----+\n",
      "|emp3| NULL|345.0|\n",
      "|emp4|Cindy|456.0|\n",
      "+----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Subset - only check these coluumns\n",
    "df.na.drop(subset=['Sales']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c770251-7e93-4d8b-aae2-7a3e66e3ae52",
   "metadata": {},
   "source": [
    "### Fill in missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d02678a-4c6d-4393-91be-063678ee36c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------+-----+\n",
      "|  Id|       Name|Sales|\n",
      "+----+-----------+-----+\n",
      "|emp1|       John| NULL|\n",
      "|emp2|FILL VALUES| NULL|\n",
      "|emp3|FILL VALUES|345.0|\n",
      "|emp4|      Cindy|456.0|\n",
      "+----+-----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Spark is type smart. Will only fill in matching values\n",
    "df.na.fill('FILL VALUES').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b01c4c08-90ef-459f-b731-2a4250e90962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----+\n",
      "|  Id| Name|Sales|\n",
      "+----+-----+-----+\n",
      "|emp1| John|  0.0|\n",
      "|emp2| NULL|  0.0|\n",
      "|emp3| NULL|345.0|\n",
      "|emp4|Cindy|456.0|\n",
      "+----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.na.fill(0).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6cf5455f-f74f-4a3e-98ac-7b7856246313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+-----+\n",
      "|  Id|   Name|Sales|\n",
      "+----+-------+-----+\n",
      "|emp1|   John| NULL|\n",
      "|emp2|No Name| NULL|\n",
      "|emp3|No Name|345.0|\n",
      "|emp4|  Cindy|456.0|\n",
      "+----+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Specify col\n",
    "df.na.fill('No Name', subset=['Name']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "83bf9abe-10e2-4c1f-a277-9a27bd5ffdf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(avg(Sales)=400.5)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use average\n",
    "avg_sales = df.agg({'Sales': 'avg'}).collect()\n",
    "avg_sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cb6c520e-0e2a-4b08-ac79-9edb6e801559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400.5"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_sales = avg_sales[0][0]\n",
    "avg_sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6bbcddfa-76ab-4e0f-8933-2a03424bae0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----+\n",
      "|  Id| Name|Sales|\n",
      "+----+-----+-----+\n",
      "|emp1| John|400.5|\n",
      "|emp2| NULL|400.5|\n",
      "|emp3| NULL|345.0|\n",
      "|emp4|Cindy|456.0|\n",
      "+----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.na.fill(avg_sales, subset=['Sales']).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
